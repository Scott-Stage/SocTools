Got it — if there’s no need for base URL resolution and you just want every link present in the raw HTML, we can make the function simpler.

Here’s a straightforward version:

```csharp
using System;
using System.Collections.Generic;
using System.Text.RegularExpressions;
using System.Web;

public static class HtmlUrlExtractor
{
    /// <summary>
    /// Extracts all URLs from href, src, and CSS url(...) in raw HTML.
    /// </summary>
    public static List<string> ExtractUrls(string html)
    {
        if (string.IsNullOrWhiteSpace(html))
            return new List<string>();

        var urls = new HashSet<string>(StringComparer.OrdinalIgnoreCase);

        // 1) Common HTML attributes (href, src, data-src, poster, action)
        var attrRegex = new Regex(
            @"\b(?:href|src|data-src|poster|action)\s*=\s*(?:""(?<u>[^""]+)""|'(?<u>[^']+)'|(?<u>[^\s>]+))",
            RegexOptions.IgnoreCase | RegexOptions.Singleline | RegexOptions.Compiled);

        foreach (Match m in attrRegex.Matches(html))
        {
            var u = HttpUtility.HtmlDecode(m.Groups["u"].Value.Trim());
            if (!string.IsNullOrEmpty(u))
                urls.Add(u);
        }

        // 2) CSS url(...)
        var cssUrlRegex = new Regex(
            @"url\(\s*(?:['""])?(?<u>[^'""\)]+)(?:['""])?\s*\)",
            RegexOptions.IgnoreCase | RegexOptions.Singleline | RegexOptions.Compiled);

        foreach (Match m in cssUrlRegex.Matches(html))
        {
            var u = HttpUtility.HtmlDecode(m.Groups["u"].Value.Trim());
            if (!string.IsNullOrEmpty(u))
                urls.Add(u);
        }

        // 3) Naked http(s) links in text
        var nakedUrlRegex = new Regex(
            @"https?://[^\s'""<>)]+",
            RegexOptions.IgnoreCase | RegexOptions.Singleline | RegexOptions.Compiled);

        foreach (Match m in nakedUrlRegex.Matches(html))
        {
            urls.Add(m.Value);
        }

        return new List<string>(urls);
    }
}
```

### Usage:

```csharp
string html = "<a href='https://example.com'>Link</a><img src=\"/images/pic.jpg\">";
List<string> links = HtmlUrlExtractor.ExtractUrls(html);

foreach (var link in links)
{
    Console.WriteLine(link);
}
```

### Key Points:

* Captures:

  * `href`, `src`, `data-src`, `poster`, `action` attributes.
  * CSS `url(...)` patterns.
  * Naked `http://` or `https://` links in text.
* Avoids duplicates using `HashSet<string>`.
* Keeps URLs exactly as found (absolute or relative).

If you want, I can also make a **version using HtmlAgilityPack** that is more robust and immune to tricky HTML formatting. That would handle malformed HTML far better than regex alone. Would you like me to provide that parser-based version?
